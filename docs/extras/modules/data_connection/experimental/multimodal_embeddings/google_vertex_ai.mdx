# Google Vertex AI

:::info Experimental
This API is new and may change in future LangChainJS versions.
:::

The `GoogleVertexAIMultimodalEmbeddings` class provides additional methods that are
parallels to the `embedDocuments()` and `embedQuery()` methods:

- `embedImage()` and `embedImageQuery()` take node `Buffer` objects that are expected to
  contain an image.
- `embedMedia()` and `embedMediaQuery()` take an object that contain a `text` string
  field, an `image` Buffer field, or both and returns a similarly constructed object
  containing the respective vectors.

**Note:** The Google Vertex AI embeddings models have different vector sizes
than OpenAI's standard model, so some vector stores may not handle them correctly.

- The `textembedding-gecko` model in `GoogleVertexAIEmbeddings` provides 768 dimensions.
- The `multimodalembedding@001` model in `GoogleVertexAIMultimodalEmbeddings` provides 1408 dimensions.

## Usage

Here's a basic example that shows how to embed image queries:

import GoogleVertexAIMultimodalExample from "@examples/models/embeddings/googlevertexai_multimodal.ts";

import CodeBlock from "@theme/CodeBlock";

<CodeBlock language="typescript">{GoogleVertexAIMultimodalExample}</CodeBlock>

## Advanced usage

Here's a more advanced example that shows how to integrate these new embeddings with a LangChain vector store.

import GoogleVertexAIMultimodalAdvancedExample from "@examples/models/embeddings/googlevertexai_multimodal_advanced.ts";

<CodeBlock language="typescript">{GoogleVertexAIMultimodalAdvancedExample}</CodeBlock>
